{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f23e8c0",
   "metadata": {},
   "source": [
    "# 0.\n",
    "- 1.2절에서 우는 불확실성을 정량화고 조작하는 수학적인 토대로서의 확률론에 대해 살펴봤다.\n",
    "- 이제부터는 결정 이론(decision theory)에 대해 살핀다.\n",
    "- 앞으로 결정 이론과 확률론을 함께 사용하면 최적의 의사 결정을 내릴 수 있다.\n",
    "- 우리의 목표는 항상 똑같다. 입력 벡터 x와 변수 벡터 t가 존재하는 상황에서 새로운 입력 벡터 x가 주어졌을 때 타깃 변수 벡터 t를 예측하는 문제를 해결\n",
    "- 회귀일 경우 -> t가 연속 변수// 분류 문제 -> t가 클래스의 라벨에 해당\n",
    "- 결합 확률 분포 p(x,t)는 변수들의 전체 불확실성을 요약해서 나타내 준다.\n",
    "- 주어진 훈련 집합 데이터에서 p(x,t)를 찾는 것이 => 추론 문제\n",
    "- 이런 확률 정보를 바탕으로 최적의 결정을 만들어 내는 것이 결정 이론이다.\n",
    "- 이제 본격적으로 들어가보겠다. 다음은 예시가 써있는 듯하다.\n",
    "\n",
    "# 1. 시작\n",
    "- ex) 환자가 암에 걸렸는지 안 걸렸는지 판단 하는 진단 문제를 고려해보자.\n",
    "    - x는 이미지의 픽셀 강도 집합이고 , t는 환자가 암에 걸렸는지 판단하는 label \n",
    "    - 암에 걸렸을 경우 C1 , 그렇지 않으면 C2\n",
    "    - 해당 상황에 대해 가장 완전하고 확률적인 설명을 알려주는 것이 결합 확률 분포이다.\n",
    "    - 결합 확률 분포도 중요하지만 격국 우리가 하고 싶은 것은 환자를 치료할지 말지를 결정하는 것이다. 이게 바로 **결정이론**이다.\n",
    "    - 이미지가 주어졌을 때 각각의 클래스의 조건부 확률을 알아내고 싶으면 이는 $p(C_k|x)$로 표현된다.\n",
    "    - 베이지안 정리를 사용하면\n",
    "        - $p(C_k|x) = \\frac{p(x|C_k)p(C_k)}{p(x)}$\n",
    "    - 베이지안 정리에서 사용하는 모든 값들은 결합 확률 분포 $p(x,C_k)$를 활용하여 구한다.\n",
    "        - $p(C_k)$는 클래스 $C_k$에 포함될 사전 확률\n",
    "        - $p(C_k|x)$는 사후 확률\n",
    "    - 우리가 x를 잘못된 클래스에 포함시킬 가능성을 최소화 하는 것이라면, 직관적으로 우리는 높은 사후 확률을 가진 클래스를 고를것이다.\n",
    "    - 나중에 말하겠지만 이 직관은 사실 정답이다.ㅎㅎ 나중에 설명 잘해준다고 한다.\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
