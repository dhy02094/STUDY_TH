{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f185fb20",
   "metadata": {},
   "source": [
    "RNN : 음성 인식과 자연어 처리같은 순차적 데이터에 사용되는 LSTM or GRU의 근간이 되는 모델\n",
    "\n",
    "입력층 → 출력층 으로 보내는 동시에 다음 시점의 은닉층 으로도 입력이 흐르는 형태\n",
    "\n",
    "![https://wikidocs.net/images/page/22886/rnn_image2_ver3.PNG](https://wikidocs.net/images/page/22886/rnn_image2_ver3.PNG)\n",
    "\n",
    "이 사진에서 확인하듯이 $x_t$ 입력데이터와 $h_{t-1}$을 입력받아서 다음 가중치를 이용해 최종값을 출력한다.\n",
    "\n",
    "- 은닉층(RNN Cell) : $h_t = tanh(W_xx_t + W_hh_{t-1})$\n",
    "- 출력층 : $y_t = f_y(W_hh_t)$\n",
    "\n",
    "RNN은 다양한 입력, 출력 시퀀스에 따라 유연하게 네트워크 구조를 설계할 수 있으며, 그만큼 여러문제에 적용가능.\n",
    "\n",
    "- One to Many : Image Captioning(이미지를 설명하는 문장을 생성하는 문제)\n",
    "- Many to One : sentiment Classification (텍스트에서 정보를 추출하여 감정, 태도 파악)\n",
    "- Many to Many : 동영상의 각 이미지 프레임별 분류\n",
    "- Delayed Many to Many : Machine Translation(입력된 언어를 다른언어로 변환하는 기계번역)\n",
    "\n",
    "![https://miro.medium.com/max/1400/1*MaU7jhH8XYo0w-F8HfGgNw.png](https://miro.medium.com/max/1400/1*MaU7jhH8XYo0w-F8HfGgNw.png)\n",
    "\n",
    "RNN에 대해 간단하게만 공부하고 넘어가겠다. 실제로 이것 관련한 프로젝트를 할 일이 있다면 추가로 정리하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d5d6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
