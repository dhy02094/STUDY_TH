{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis.ipynb",
      "provenance": [],
      "mount_file_id": "1lUdfrLRmTIoX0mxsFiXIDKk_9SMr3VOz",
      "authorship_tag": "ABX9TyPfBBmcpXDBWKYpDLGaEYLR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhy02094/STUDY_TH/blob/master/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "wg6Xrxgy3f24",
        "outputId": "0361b68f-486d-4621-adf0-52fb9fe25395"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파일 크기 : \n",
            "labeledTrainData.tsv          33.56MB\n",
            "unlabeledTrainData.tsv        67.28MB\n",
            "testData.tsv                  32.72MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id  sentiment                                             review\n",
              "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
              "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
              "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
              "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
              "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a51dfbb6-b0df-425e-87fe-d4802332dffb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"5814_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"With all this stuff going down at the moment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"2381_9\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"7759_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"3630_4\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"It must be assumed that those who praised thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"9495_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a51dfbb6-b0df-425e-87fe-d4802332dffb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a51dfbb6-b0df-425e-87fe-d4802332dffb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a51dfbb6-b0df-425e-87fe-d4802332dffb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# 압축 풀기\n",
        "\n",
        "# import zipfile\n",
        "# DATA_IN_PATH = '/content/drive/MyDrive/Kt/data_in/'\n",
        "# file_list = ['labeledTrainData.tsv.zip', 'unlabeledTrainData.tsv.zip', 'testData.tsv.zip']\n",
        "\n",
        "# for file in file_list:\n",
        "#     zipRef = zipfile.ZipFile(DATA_IN_PATH + file, 'r')\n",
        "#     zipRef.extractall(DATA_IN_PATH)\n",
        "#     zipRef.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"파일 크기 : \")\n",
        "for file in os.listdir(DATA_IN_PATH):\n",
        "    if 'tsv' in file and 'zip' not in file:\n",
        "        print(file.ljust(30) + str(round(os.path.getsize(DATA_IN_PATH + file) / 1000000, 2)) + 'MB')\n",
        "\n",
        "train_data = pd.read_csv( DATA_IN_PATH + 'labeledTrainData.tsv', header = 0, delimiter = '\\t', quoting=3)\n",
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "H4C3QuTC9MlE",
        "outputId": "87943fe9-f796-47f3-e620-449216854904"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파일 크기 : \n",
            "labeledTrainData.tsv          33.56MB\n",
            "unlabeledTrainData.tsv        67.28MB\n",
            "testData.tsv                  32.72MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id  sentiment                                             review\n",
              "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
              "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
              "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
              "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
              "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9801c5d7-d513-4c71-a8de-ffc01485697e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"5814_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"With all this stuff going down at the moment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"2381_9\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"7759_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"3630_4\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"It must be assumed that those who praised thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"9495_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9801c5d7-d513-4c71-a8de-ffc01485697e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9801c5d7-d513-4c71-a8de-ffc01485697e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9801c5d7-d513-4c71-a8de-ffc01485697e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('전체 학습데이터의 개수 : {}'.format(len(train_data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IU5PdBha50U1",
        "outputId": "3b110664-607c-437c-eae6-9e1c840392ad"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 학습데이터의 개수 : 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_length = train_data['review'].apply(len)\n",
        "train_length.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os8s9oM_7hSS",
        "outputId": "e96529b3-8def-47ea-827f-63a4454da1b8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2304\n",
              "1     948\n",
              "2    2451\n",
              "3    2247\n",
              "4    2233\n",
              "Name: review, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "step2 preprocessing"
      ],
      "metadata": {
        "id": "gxUeMj1NP3Pj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re \n",
        "import json \n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import nltk \n",
        "from bs4 import BeautifulSoup \n",
        "from nltk.corpus import stopwords \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n"
      ],
      "metadata": {
        "id": "PDCOSMt37hM0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_IN_PATH = '/content/drive/MyDrive/Kt/data_in/'\n",
        "train_data = pd.read_csv( DATA_IN_PATH + 'labeledTrainData.tsv', header = 0, delimiter = '\\t', quoting=3)\n",
        "\n",
        "review = train_data['review'][0] #첫 번째 리뷰를 가져옴\n",
        "review_text = BeautifulSoup(review,'html5lib').get_text()   #HTML 태그 제거\n",
        "review_text = re.sub(\"[^a-zA-Z]\", \" \", review_text)        #영어 문자를 제외한 나머지는 모두 공백으로 바꿈\n",
        "print(review_text)\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))    # 영어 불용어 집합 구성\n",
        "\n",
        "review_text = review_text.lower()\n",
        "words = review_text.split()                     # 소문자로 바꿔서 단어 리스트로 만듦\n",
        "words = [w for w in words if not w in stop_words]\n",
        "print(words)\n",
        "clean_review = ' '.join(words)                 # 단어 리스트들을 다시 하나의 글로\n",
        "print(clean_review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBbeBCgvPTnr",
        "outputId": "1c89818d-9563-41fa-e7e3-8fc86188fdfe"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " With all this stuff going down at the moment with MJ i ve started listening to his music  watching the odd documentary here and there  watched The Wiz and watched Moonwalker again  Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent  Moonwalker is part biography  part feature film which i remember going to see at the cinema when it was originally released  Some of it has subtle messages about MJ s feeling towards the press and also the obvious message of drugs are bad m kay Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring  Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him The actual feature film bit when it finally starts is only on for    minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord  Why he wants MJ dead so bad is beyond me  Because MJ overheard his plans  Nah  Joe Pesci s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno  maybe he just hates MJ s music Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence  Also  the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene Bottom line  this movie is for people who like MJ on one level or another  which i think is most people   If not  then stay away  It does try and give off a wholesome message and ironically MJ s bestest buddy in this movie is a girl  Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty  Well  with all the attention i ve gave this subject    hmmm well i don t know because people can be different behind closed doors  i know this for a fact  He is either an extremely nice but stupid guy or one of the most sickest liars  I hope he is not the latter  \n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['stuff', 'going', 'moment', 'mj', 'started', 'listening', 'music', 'watching', 'odd', 'documentary', 'watched', 'wiz', 'watched', 'moonwalker', 'maybe', 'want', 'get', 'certain', 'insight', 'guy', 'thought', 'really', 'cool', 'eighties', 'maybe', 'make', 'mind', 'whether', 'guilty', 'innocent', 'moonwalker', 'part', 'biography', 'part', 'feature', 'film', 'remember', 'going', 'see', 'cinema', 'originally', 'released', 'subtle', 'messages', 'mj', 'feeling', 'towards', 'press', 'also', 'obvious', 'message', 'drugs', 'bad', 'kay', 'visually', 'impressive', 'course', 'michael', 'jackson', 'unless', 'remotely', 'like', 'mj', 'anyway', 'going', 'hate', 'find', 'boring', 'may', 'call', 'mj', 'egotist', 'consenting', 'making', 'movie', 'mj', 'fans', 'would', 'say', 'made', 'fans', 'true', 'really', 'nice', 'actual', 'feature', 'film', 'bit', 'finally', 'starts', 'minutes', 'excluding', 'smooth', 'criminal', 'sequence', 'joe', 'pesci', 'convincing', 'psychopathic', 'powerful', 'drug', 'lord', 'wants', 'mj', 'dead', 'bad', 'beyond', 'mj', 'overheard', 'plans', 'nah', 'joe', 'pesci', 'character', 'ranted', 'wanted', 'people', 'know', 'supplying', 'drugs', 'etc', 'dunno', 'maybe', 'hates', 'mj', 'music', 'lots', 'cool', 'things', 'like', 'mj', 'turning', 'car', 'robot', 'whole', 'speed', 'demon', 'sequence', 'also', 'director', 'must', 'patience', 'saint', 'came', 'filming', 'kiddy', 'bad', 'sequence', 'usually', 'directors', 'hate', 'working', 'one', 'kid', 'let', 'alone', 'whole', 'bunch', 'performing', 'complex', 'dance', 'scene', 'bottom', 'line', 'movie', 'people', 'like', 'mj', 'one', 'level', 'another', 'think', 'people', 'stay', 'away', 'try', 'give', 'wholesome', 'message', 'ironically', 'mj', 'bestest', 'buddy', 'movie', 'girl', 'michael', 'jackson', 'truly', 'one', 'talented', 'people', 'ever', 'grace', 'planet', 'guilty', 'well', 'attention', 'gave', 'subject', 'hmmm', 'well', 'know', 'people', 'different', 'behind', 'closed', 'doors', 'know', 'fact', 'either', 'extremely', 'nice', 'stupid', 'guy', 'one', 'sickest', 'liars', 'hope', 'latter']\n",
            "stuff going moment mj started listening music watching odd documentary watched wiz watched moonwalker maybe want get certain insight guy thought really cool eighties maybe make mind whether guilty innocent moonwalker part biography part feature film remember going see cinema originally released subtle messages mj feeling towards press also obvious message drugs bad kay visually impressive course michael jackson unless remotely like mj anyway going hate find boring may call mj egotist consenting making movie mj fans would say made fans true really nice actual feature film bit finally starts minutes excluding smooth criminal sequence joe pesci convincing psychopathic powerful drug lord wants mj dead bad beyond mj overheard plans nah joe pesci character ranted wanted people know supplying drugs etc dunno maybe hates mj music lots cool things like mj turning car robot whole speed demon sequence also director must patience saint came filming kiddy bad sequence usually directors hate working one kid let alone whole bunch performing complex dance scene bottom line movie people like mj one level another think people stay away try give wholesome message ironically mj bestest buddy movie girl michael jackson truly one talented people ever grace planet guilty well attention gave subject hmmm well know people different behind closed doors know fact either extremely nice stupid guy one sickest liars hope latter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(review, remove_stopwords=False):\n",
        "    review_text = BeautifulSoup(review, \"html5lib\").get_text()\n",
        "    review_text = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
        "    review_text = review_text.lower()\n",
        "    if remove_stopwords:\n",
        "        words = review_text.split()\n",
        "        stops = set(stopwords.words('english'))\n",
        "        words = [w for w in words if not w in stops]\n",
        "        review_text = ' '.join(words)\n",
        "    return review_text\n",
        "\n",
        "clean_train_reviews = []\n",
        "for review in train_data['review']:\n",
        "    clean_train_reviews.append(preprocessing(review, remove_stopwords = True))\n",
        "clean_train_df = pd.DataFrame({'review' : clean_train_reviews,\n",
        "                               'sentiment' : train_data['sentiment']})\n"
      ],
      "metadata": {
        "id": "LOLrmDM1W365"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "z4NlouU7aFf3",
        "outputId": "c40ca3a3-557a-43b0-c186-380b754530d6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review  sentiment\n",
              "0      stuff going moment mj started listening music ...          1\n",
              "1      classic war worlds timothy hines entertaining ...          1\n",
              "2      film starts manager nicholas bell giving welco...          0\n",
              "3      must assumed praised film greatest filmed oper...          0\n",
              "4      superbly trashy wondrously unpretentious explo...          1\n",
              "...                                                  ...        ...\n",
              "24995  seems like consideration gone imdb reviews fil...          0\n",
              "24996  believe made film completely unnecessary first...          0\n",
              "24997  guy loser get girls needs build picked stronge...          0\n",
              "24998  minute documentary bu uel made early one spain...          0\n",
              "24999  saw movie child broke heart story unfinished e...          1\n",
              "\n",
              "[25000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1ff9119-8850-4095-b277-171008ea5280\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>stuff going moment mj started listening music ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>classic war worlds timothy hines entertaining ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>film starts manager nicholas bell giving welco...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>must assumed praised film greatest filmed oper...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>superbly trashy wondrously unpretentious explo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>seems like consideration gone imdb reviews fil...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>believe made film completely unnecessary first...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>guy loser get girls needs build picked stronge...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>minute documentary bu uel made early one spain...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>saw movie child broke heart story unfinished e...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1ff9119-8850-4095-b277-171008ea5280')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d1ff9119-8850-4095-b277-171008ea5280 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d1ff9119-8850-4095-b277-171008ea5280');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(clean_train_reviews)\n",
        "text_sequences = tokenizer.texts_to_sequences(clean_train_reviews)\n",
        "print(text_sequences[0])\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 174\n",
        "train_inputs = pad_sequences(text_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
        "print('Train Data:', train_inputs.shape)\n",
        "\n",
        "train_labels = np.array(train_data['sentiment'])\n",
        "print('Label:', train_labels.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NL-9g6KJ7g_o",
        "outputId": "1d270081-9877-4c0c-8e81-bf34a56f8dee"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[404, 70, 419, 8815, 506, 2456, 115, 54, 873, 516, 178, 18686, 178, 11242, 165, 78, 14, 662, 2457, 117, 92, 10, 499, 4074, 165, 22, 210, 581, 2333, 1194, 11242, 71, 4826, 71, 635, 2, 253, 70, 11, 302, 1663, 486, 1144, 3265, 8815, 411, 793, 3342, 17, 441, 600, 1500, 15, 4424, 1851, 998, 146, 342, 1442, 743, 2424, 4, 8815, 418, 70, 637, 69, 237, 94, 541, 8815, 26055, 26056, 120, 1, 8815, 323, 8, 47, 20, 323, 167, 10, 207, 633, 635, 2, 116, 291, 382, 121, 15535, 3315, 1501, 574, 734, 10013, 923, 11578, 822, 1239, 1408, 360, 8815, 221, 15, 576, 8815, 22224, 2274, 13426, 734, 10013, 27, 28606, 340, 16, 41, 18687, 1500, 388, 11243, 165, 3962, 8815, 115, 627, 499, 79, 4, 8815, 1430, 380, 2163, 114, 1919, 2503, 574, 17, 60, 100, 4875, 5100, 260, 1268, 26057, 15, 574, 493, 744, 637, 631, 3, 394, 164, 446, 114, 615, 3266, 1160, 684, 48, 1175, 224, 1, 16, 4, 8815, 3, 507, 62, 25, 16, 640, 133, 231, 95, 7426, 600, 3439, 8815, 37248, 1864, 1, 128, 342, 1442, 247, 3, 865, 16, 42, 1487, 997, 2333, 12, 549, 386, 717, 6920, 12, 41, 16, 158, 362, 4392, 3388, 41, 87, 225, 438, 207, 254, 117, 3, 18688, 18689, 316, 1356]\n",
            "Train Data: (25000, 174)\n",
            "Label: (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "reviews = list(train_data['review'])\n",
        "sentiments = list(train_data['sentiment'])\n",
        "vectorizer = TfidfVectorizer(min_df = 0.0, analyzer=\"char\", sublinear_tf=True, ngram_range=(1,3), max_features=5000)\n",
        "X = vectorizer.fit_transform(reviews)\n",
        "y = np.array(sentiments)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "lgs = LogisticRegression(class_weight='balanced')\n",
        "lgs.fit(X_train, y_train)\n",
        "print('Accuracy: %f' % lgs.score(X_test, y_test))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XksYY3brdlTX",
        "outputId": "b86c7b28-3192-4212-8066-9559f1a2df5e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 5000) (5000, 5000) (20000,) (5000,)\n",
            "Accuracy: 0.869600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "X_train1 = X_train.toarray()\n",
        "X_test1 = X_test.toarray()\n",
        "# Model, Cost, Train\n",
        "model = Sequential()\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "model.fit(X_train1, y_train, epochs=200, verbose=1)\n",
        "\n",
        "#Testing\n",
        "_, accuracy = model.evaluate(X_test1, y_test)\n",
        "print('Accuracy: ', accuracy)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnGR5r9Ag3do",
        "outputId": "362d1edd-4af9-43ca-fe74-5dfa9c49d4ba"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "625/625 [==============================] - 13s 20ms/step - loss: 0.6924 - accuracy: 0.5252\n",
            "Epoch 2/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.6902 - accuracy: 0.6248\n",
            "Epoch 3/200\n",
            "625/625 [==============================] - 9s 15ms/step - loss: 0.6880 - accuracy: 0.6676\n",
            "Epoch 4/200\n",
            "625/625 [==============================] - 9s 15ms/step - loss: 0.6854 - accuracy: 0.6801\n",
            "Epoch 5/200\n",
            "625/625 [==============================] - 9s 15ms/step - loss: 0.6825 - accuracy: 0.6913\n",
            "Epoch 6/200\n",
            "625/625 [==============================] - 9s 15ms/step - loss: 0.6791 - accuracy: 0.7477\n",
            "Epoch 7/200\n",
            "625/625 [==============================] - 10s 15ms/step - loss: 0.6749 - accuracy: 0.7569\n",
            "Epoch 8/200\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.6699 - accuracy: 0.7508\n",
            "Epoch 9/200\n",
            "625/625 [==============================] - 9s 15ms/step - loss: 0.6643 - accuracy: 0.7612\n",
            "Epoch 10/200\n",
            "625/625 [==============================] - 10s 15ms/step - loss: 0.6576 - accuracy: 0.7753\n",
            "Epoch 11/200\n",
            "625/625 [==============================] - 10s 15ms/step - loss: 0.6499 - accuracy: 0.7815\n",
            "Epoch 12/200\n",
            "625/625 [==============================] - 9s 15ms/step - loss: 0.6411 - accuracy: 0.7849\n",
            "Epoch 13/200\n",
            "625/625 [==============================] - 9s 15ms/step - loss: 0.6310 - accuracy: 0.7843\n",
            "Epoch 14/200\n",
            "625/625 [==============================] - 10s 15ms/step - loss: 0.6196 - accuracy: 0.7878\n",
            "Epoch 15/200\n",
            "625/625 [==============================] - 9s 15ms/step - loss: 0.6075 - accuracy: 0.7939\n",
            "Epoch 16/200\n",
            "625/625 [==============================] - 10s 15ms/step - loss: 0.5943 - accuracy: 0.7949\n",
            "Epoch 17/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.5802 - accuracy: 0.8011\n",
            "Epoch 18/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.5658 - accuracy: 0.8031\n",
            "Epoch 19/200\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.5509 - accuracy: 0.8065\n",
            "Epoch 20/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.5360 - accuracy: 0.8101\n",
            "Epoch 21/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.5212 - accuracy: 0.8150\n",
            "Epoch 22/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.5068 - accuracy: 0.8189\n",
            "Epoch 23/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.4930 - accuracy: 0.8209\n",
            "Epoch 24/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.4797 - accuracy: 0.8248\n",
            "Epoch 25/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.4671 - accuracy: 0.8288\n",
            "Epoch 26/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.4552 - accuracy: 0.8313\n",
            "Epoch 27/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.4443 - accuracy: 0.8343\n",
            "Epoch 28/200\n",
            "625/625 [==============================] - 10s 15ms/step - loss: 0.4339 - accuracy: 0.8380\n",
            "Epoch 29/200\n",
            "625/625 [==============================] - 10s 17ms/step - loss: 0.4241 - accuracy: 0.8407\n",
            "Epoch 30/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.4154 - accuracy: 0.8439\n",
            "Epoch 31/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.4071 - accuracy: 0.8450\n",
            "Epoch 32/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3992 - accuracy: 0.8487\n",
            "Epoch 33/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3918 - accuracy: 0.8505\n",
            "Epoch 34/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3856 - accuracy: 0.8523\n",
            "Epoch 35/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3792 - accuracy: 0.8539\n",
            "Epoch 36/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3735 - accuracy: 0.8559\n",
            "Epoch 37/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3683 - accuracy: 0.8577\n",
            "Epoch 38/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3634 - accuracy: 0.8589\n",
            "Epoch 39/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3586 - accuracy: 0.8602\n",
            "Epoch 40/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3543 - accuracy: 0.8605\n",
            "Epoch 41/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3502 - accuracy: 0.8620\n",
            "Epoch 42/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3462 - accuracy: 0.8630\n",
            "Epoch 43/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3425 - accuracy: 0.8647\n",
            "Epoch 44/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3390 - accuracy: 0.8655\n",
            "Epoch 45/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3359 - accuracy: 0.8664\n",
            "Epoch 46/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3326 - accuracy: 0.8673\n",
            "Epoch 47/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3297 - accuracy: 0.8681\n",
            "Epoch 48/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3268 - accuracy: 0.8712\n",
            "Epoch 49/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3240 - accuracy: 0.8722\n",
            "Epoch 50/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3214 - accuracy: 0.8733\n",
            "Epoch 51/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3190 - accuracy: 0.8730\n",
            "Epoch 52/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3166 - accuracy: 0.8741\n",
            "Epoch 53/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3142 - accuracy: 0.8748\n",
            "Epoch 54/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3119 - accuracy: 0.8760\n",
            "Epoch 55/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3099 - accuracy: 0.8761\n",
            "Epoch 56/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3078 - accuracy: 0.8770\n",
            "Epoch 57/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3056 - accuracy: 0.8778\n",
            "Epoch 58/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3037 - accuracy: 0.8787\n",
            "Epoch 59/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3019 - accuracy: 0.8799\n",
            "Epoch 60/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.3000 - accuracy: 0.8808\n",
            "Epoch 61/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2982 - accuracy: 0.8805\n",
            "Epoch 62/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2965 - accuracy: 0.8820\n",
            "Epoch 63/200\n",
            "625/625 [==============================] - 12s 19ms/step - loss: 0.2949 - accuracy: 0.8825\n",
            "Epoch 64/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2929 - accuracy: 0.8837\n",
            "Epoch 65/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2915 - accuracy: 0.8845\n",
            "Epoch 66/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2901 - accuracy: 0.8847\n",
            "Epoch 67/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2882 - accuracy: 0.8860\n",
            "Epoch 68/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2870 - accuracy: 0.8867\n",
            "Epoch 69/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2855 - accuracy: 0.8870\n",
            "Epoch 70/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2840 - accuracy: 0.8888\n",
            "Epoch 71/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2825 - accuracy: 0.8878\n",
            "Epoch 72/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2813 - accuracy: 0.8881\n",
            "Epoch 73/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2800 - accuracy: 0.8885\n",
            "Epoch 74/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2786 - accuracy: 0.8906\n",
            "Epoch 75/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2770 - accuracy: 0.8903\n",
            "Epoch 76/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2762 - accuracy: 0.8905\n",
            "Epoch 77/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2748 - accuracy: 0.8921\n",
            "Epoch 78/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2736 - accuracy: 0.8920\n",
            "Epoch 79/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2723 - accuracy: 0.8919\n",
            "Epoch 80/200\n",
            "625/625 [==============================] - 10s 17ms/step - loss: 0.2713 - accuracy: 0.8931\n",
            "Epoch 81/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2703 - accuracy: 0.8925\n",
            "Epoch 82/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2690 - accuracy: 0.8943\n",
            "Epoch 83/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2682 - accuracy: 0.8941\n",
            "Epoch 84/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2669 - accuracy: 0.8957\n",
            "Epoch 85/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2656 - accuracy: 0.8952\n",
            "Epoch 86/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2647 - accuracy: 0.8965\n",
            "Epoch 87/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2636 - accuracy: 0.8963\n",
            "Epoch 88/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2628 - accuracy: 0.8967\n",
            "Epoch 89/200\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.2617 - accuracy: 0.8985\n",
            "Epoch 90/200\n",
            "625/625 [==============================] - 11s 18ms/step - loss: 0.2606 - accuracy: 0.8980\n",
            "Epoch 91/200\n",
            "625/625 [==============================] - 12s 18ms/step - loss: 0.2597 - accuracy: 0.8973\n",
            "Epoch 92/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2588 - accuracy: 0.8979\n",
            "Epoch 93/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2581 - accuracy: 0.8997\n",
            "Epoch 94/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2570 - accuracy: 0.8992\n",
            "Epoch 95/200\n",
            "625/625 [==============================] - 10s 15ms/step - loss: 0.2562 - accuracy: 0.9004\n",
            "Epoch 96/200\n",
            "625/625 [==============================] - 10s 15ms/step - loss: 0.2553 - accuracy: 0.8996\n",
            "Epoch 97/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2543 - accuracy: 0.9007\n",
            "Epoch 98/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2534 - accuracy: 0.9006\n",
            "Epoch 99/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2526 - accuracy: 0.9011\n",
            "Epoch 100/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2517 - accuracy: 0.9025\n",
            "Epoch 101/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2510 - accuracy: 0.9019\n",
            "Epoch 102/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2499 - accuracy: 0.9025\n",
            "Epoch 103/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2495 - accuracy: 0.9018\n",
            "Epoch 104/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2486 - accuracy: 0.9032\n",
            "Epoch 105/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2477 - accuracy: 0.9037\n",
            "Epoch 106/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2472 - accuracy: 0.9028\n",
            "Epoch 107/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2461 - accuracy: 0.9031\n",
            "Epoch 108/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2453 - accuracy: 0.9036\n",
            "Epoch 109/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2446 - accuracy: 0.9046\n",
            "Epoch 110/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2439 - accuracy: 0.9054\n",
            "Epoch 111/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2433 - accuracy: 0.9054\n",
            "Epoch 112/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2426 - accuracy: 0.9042\n",
            "Epoch 113/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2420 - accuracy: 0.9047\n",
            "Epoch 114/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2412 - accuracy: 0.9061\n",
            "Epoch 115/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2406 - accuracy: 0.9057\n",
            "Epoch 116/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2399 - accuracy: 0.9060\n",
            "Epoch 117/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2395 - accuracy: 0.9060\n",
            "Epoch 118/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2383 - accuracy: 0.9067\n",
            "Epoch 119/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2378 - accuracy: 0.9071\n",
            "Epoch 120/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2373 - accuracy: 0.9073\n",
            "Epoch 121/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2366 - accuracy: 0.9071\n",
            "Epoch 122/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2361 - accuracy: 0.9075\n",
            "Epoch 123/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2355 - accuracy: 0.9086\n",
            "Epoch 124/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2346 - accuracy: 0.9082\n",
            "Epoch 125/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2340 - accuracy: 0.9097\n",
            "Epoch 126/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2336 - accuracy: 0.9090\n",
            "Epoch 127/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2329 - accuracy: 0.9092\n",
            "Epoch 128/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2323 - accuracy: 0.9086\n",
            "Epoch 129/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2318 - accuracy: 0.9101\n",
            "Epoch 130/200\n",
            "625/625 [==============================] - 10s 17ms/step - loss: 0.2309 - accuracy: 0.9103\n",
            "Epoch 131/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2306 - accuracy: 0.9101\n",
            "Epoch 132/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2301 - accuracy: 0.9107\n",
            "Epoch 133/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2295 - accuracy: 0.9107\n",
            "Epoch 134/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2291 - accuracy: 0.9101\n",
            "Epoch 135/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2283 - accuracy: 0.9104\n",
            "Epoch 136/200\n",
            "625/625 [==============================] - 10s 17ms/step - loss: 0.2278 - accuracy: 0.9117\n",
            "Epoch 137/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2271 - accuracy: 0.9115\n",
            "Epoch 138/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2269 - accuracy: 0.9125\n",
            "Epoch 139/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2259 - accuracy: 0.9122\n",
            "Epoch 140/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2259 - accuracy: 0.9121\n",
            "Epoch 141/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2254 - accuracy: 0.9122\n",
            "Epoch 142/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2247 - accuracy: 0.9135\n",
            "Epoch 143/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2239 - accuracy: 0.9124\n",
            "Epoch 144/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2236 - accuracy: 0.9136\n",
            "Epoch 145/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2233 - accuracy: 0.9137\n",
            "Epoch 146/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2227 - accuracy: 0.9140\n",
            "Epoch 147/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2224 - accuracy: 0.9141\n",
            "Epoch 148/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2220 - accuracy: 0.9141\n",
            "Epoch 149/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2213 - accuracy: 0.9150\n",
            "Epoch 150/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2207 - accuracy: 0.9151\n",
            "Epoch 151/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2201 - accuracy: 0.9151\n",
            "Epoch 152/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2196 - accuracy: 0.9146\n",
            "Epoch 153/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2191 - accuracy: 0.9152\n",
            "Epoch 154/200\n",
            "625/625 [==============================] - 10s 17ms/step - loss: 0.2189 - accuracy: 0.9165\n",
            "Epoch 155/200\n",
            "625/625 [==============================] - 10s 17ms/step - loss: 0.2184 - accuracy: 0.9156\n",
            "Epoch 156/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2183 - accuracy: 0.9154\n",
            "Epoch 157/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2178 - accuracy: 0.9154\n",
            "Epoch 158/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2170 - accuracy: 0.9162\n",
            "Epoch 159/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2165 - accuracy: 0.9169\n",
            "Epoch 160/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2164 - accuracy: 0.9161\n",
            "Epoch 161/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2156 - accuracy: 0.9169\n",
            "Epoch 162/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2151 - accuracy: 0.9172\n",
            "Epoch 163/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2151 - accuracy: 0.9179\n",
            "Epoch 164/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2145 - accuracy: 0.9175\n",
            "Epoch 165/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2142 - accuracy: 0.9182\n",
            "Epoch 166/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2138 - accuracy: 0.9168\n",
            "Epoch 167/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2135 - accuracy: 0.9182\n",
            "Epoch 168/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2129 - accuracy: 0.9176\n",
            "Epoch 169/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2123 - accuracy: 0.9191\n",
            "Epoch 170/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2117 - accuracy: 0.9196\n",
            "Epoch 171/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2118 - accuracy: 0.9182\n",
            "Epoch 172/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2113 - accuracy: 0.9181\n",
            "Epoch 173/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2109 - accuracy: 0.9186\n",
            "Epoch 174/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2104 - accuracy: 0.9205\n",
            "Epoch 175/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2104 - accuracy: 0.9189\n",
            "Epoch 176/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2098 - accuracy: 0.9196\n",
            "Epoch 177/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2096 - accuracy: 0.9184\n",
            "Epoch 178/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2092 - accuracy: 0.9195\n",
            "Epoch 179/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2084 - accuracy: 0.9184\n",
            "Epoch 180/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2083 - accuracy: 0.9200\n",
            "Epoch 181/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2079 - accuracy: 0.9195\n",
            "Epoch 182/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2077 - accuracy: 0.9212\n",
            "Epoch 183/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2073 - accuracy: 0.9212\n",
            "Epoch 184/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2071 - accuracy: 0.9205\n",
            "Epoch 185/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2064 - accuracy: 0.9212\n",
            "Epoch 186/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2060 - accuracy: 0.9204\n",
            "Epoch 187/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2053 - accuracy: 0.9222\n",
            "Epoch 188/200\n",
            "625/625 [==============================] - 10s 17ms/step - loss: 0.2059 - accuracy: 0.9212\n",
            "Epoch 189/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2049 - accuracy: 0.9211\n",
            "Epoch 190/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2045 - accuracy: 0.9222\n",
            "Epoch 191/200\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.2043 - accuracy: 0.9220\n",
            "Epoch 192/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2039 - accuracy: 0.9223\n",
            "Epoch 193/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2035 - accuracy: 0.9223\n",
            "Epoch 194/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2035 - accuracy: 0.9219\n",
            "Epoch 195/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2028 - accuracy: 0.9236\n",
            "Epoch 196/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2026 - accuracy: 0.9215\n",
            "Epoch 197/200\n",
            "625/625 [==============================] - 10s 17ms/step - loss: 0.2021 - accuracy: 0.9241\n",
            "Epoch 198/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2021 - accuracy: 0.9223\n",
            "Epoch 199/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2020 - accuracy: 0.9221\n",
            "Epoch 200/200\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2014 - accuracy: 0.9229\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.3121 - accuracy: 0.8704\n",
            "Accuracy:  0.8704000115394592\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 500)               2500500   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 501       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,501,001\n",
            "Trainable params: 2,501,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yGNNOAw6g3bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6pEO_tL7g3ZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fH6ITjSLg3UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oP05omfug3H8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}