{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1105bdc",
   "metadata": {},
   "source": [
    "# 1.2.4 비지도학습\n",
    "\n",
    "비지도학습은 정답 혹은 레이블이 주어지지 않은 상태에서의 학습 방법.\n",
    "\n",
    "### 군집화(clstering)\n",
    "\n",
    "- 데이터를 분류하기 위한 명확한 기준이 존재하지 않은 상태에서 특징이 유사한 데이터끼리 묶어 여러 개의 군집으로 나누는 방법\n",
    "- 군집의 개수는 사전의 정의하거나 군집 정도를 나타내는 지표(Dunn Index, Silhouette)등을 이용할 수 있다.\n",
    "- 군집 내 응집도 최대화 : 동일한 군집에 소속된 개체들은 서로 유사할수록 좋음\n",
    "- 군집 간 분리도 최대화 : 상이한 군집에 소속된 개체들은 서로 다를수록 좋음\n",
    "- 대표적인 방법론 : k-Means Clustering, Hierarchical Clustering, Density-Based Spatial Clustering of Application with Noise(DBSCAN)\n",
    "\n",
    "### 차원축소(Dimensionality Reduction)\n",
    "\n",
    "- 차원이 높아질수록 학습데이터수가 차원의 수보다 적어서 성능이 저하될 때 차원의 저주에 걸렸다고 한다.\n",
    "- 부가설명을 하면 관측치는 200개인데 변수가 600개이면 좋은 성능을 가질수 없게된다.\n",
    "- 차원의 저주 해결법\n",
    "    - 변수 선택  : 갖고 있던 변수 중 일부만 선택해서 사용\n",
    "    - 변수 추출  : 변수를 조합해서 새로운 변수로 재창조\n",
    "- 대표적인 방법론 : PCA, MDS, LLE, t-SNE 등이 있고 다음 내용은 차차 알아보도록하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5de4fec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
